// Generated by ScalaBuff, the Scala Protocol Buffers compiler. DO NOT EDIT!
// source: ql2.proto

package srethink.protocol

final case class VersionDummy() extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[VersionDummy]
    with net.sandrogrzicic.scalabuff.Parser[VersionDummy] {

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): VersionDummy = {
    import com.google.protobuf.ExtensionRegistryLite.{getEmptyRegistry => _emptyRegistry}

    def __newMerged = VersionDummy(

    )
    while (true) in.readTag match {
      case 0 => return __newMerged
      case default => if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: VersionDummy) = {
    VersionDummy()
  }

  def getDefaultInstanceForType = VersionDummy.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object VersionDummy {
  @reflect.BeanProperty val defaultInstance = new VersionDummy()

  def parseFrom(data: Array[Byte]): VersionDummy = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): VersionDummy = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): VersionDummy = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): VersionDummy = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[VersionDummy] = defaultInstance.mergeDelimitedFromStream(stream)


  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: VersionDummy) = defaultInstance.mergeFrom(prototype)

  object Version extends net.sandrogrzicic.scalabuff.Enum {
    sealed trait EnumVal extends Value
    val _UNINITIALIZED = new EnumVal { val name = "UNINITIALIZED ENUM VALUE"; val id = -1 }

    val V0_1 = new EnumVal { val name = "V0_1"; val id = 1063369270 }
    val V0_2 = new EnumVal { val name = "V0_2"; val id = 1915781601 }

    val V0_1_VALUE = 1063369270
    val V0_2_VALUE = 1915781601

    def valueOf(id: Int) = id match {
      case 1063369270 => V0_1
      case 1915781601 => V0_2
      case _default => throw new net.sandrogrzicic.scalabuff.UnknownEnumException(_default)
    }
    val internalGetValueMap = new com.google.protobuf.Internal.EnumLiteMap[EnumVal] {
      def findValueByNumber(id: Int): EnumVal = valueOf(id)
    }
  }

}
final case class Query (
  `type`: Option[Query.QueryType.EnumVal] = None,
  `query`: Option[Term] = None,
  `token`: Option[Long] = None,
  `OBSOLETENoreply`: Option[Boolean] = Some(false),
  `acceptsRJson`: Option[Boolean] = Some(false),
  `globalOptargs`: scala.collection.immutable.Seq[Query.AssocPair] = Vector.empty[Query.AssocPair]
) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[Query]
    with net.sandrogrzicic.scalabuff.Parser[Query] {

  def setType(_f: Query.QueryType.EnumVal) = copy(`type` = Some(_f))
  def setQuery(_f: Term) = copy(`query` = Some(_f))
  def setToken(_f: Long) = copy(`token` = Some(_f))
  def setOBSOLETENoreply(_f: Boolean) = copy(`OBSOLETENoreply` = Some(_f))
  def setAcceptsRJson(_f: Boolean) = copy(`acceptsRJson` = Some(_f))
  def setGlobalOptargs(_i: Int, _v: Query.AssocPair) = copy(`globalOptargs` = `globalOptargs`.updated(_i, _v))
  def addGlobalOptargs(_f: Query.AssocPair) = copy(`globalOptargs` = `globalOptargs` :+ _f)
  def addAllGlobalOptargs(_f: Query.AssocPair*) = copy(`globalOptargs` = `globalOptargs` ++ _f)
  def addAllGlobalOptargs(_f: TraversableOnce[Query.AssocPair]) = copy(`globalOptargs` = `globalOptargs` ++ _f)

  def clearType = copy(`type` = None)
  def clearQuery = copy(`query` = None)
  def clearToken = copy(`token` = None)
  def clearOBSOLETENoreply = copy(`OBSOLETENoreply` = None)
  def clearAcceptsRJson = copy(`acceptsRJson` = None)
  def clearGlobalOptargs = copy(`globalOptargs` = Vector.empty[Query.AssocPair])

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    if (`type`.isDefined) output.writeEnum(1, `type`.get)
    if (`query`.isDefined) output.writeMessage(2, `query`.get)
    if (`token`.isDefined) output.writeInt64(3, `token`.get)
    if (`OBSOLETENoreply`.isDefined) output.writeBool(4, `OBSOLETENoreply`.get)
    if (`acceptsRJson`.isDefined) output.writeBool(5, `acceptsRJson`.get)
    for (_v <- `globalOptargs`) output.writeMessage(6, _v)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    if (`type`.isDefined) __size += computeEnumSize(1, `type`.get)
    if (`query`.isDefined) __size += computeMessageSize(2, `query`.get)
    if (`token`.isDefined) __size += computeInt64Size(3, `token`.get)
    if (`OBSOLETENoreply`.isDefined) __size += computeBoolSize(4, `OBSOLETENoreply`.get)
    if (`acceptsRJson`.isDefined) __size += computeBoolSize(5, `acceptsRJson`.get)
    for (_v <- `globalOptargs`) __size += computeMessageSize(6, _v)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): Query = {
    import com.google.protobuf.ExtensionRegistryLite.{getEmptyRegistry => _emptyRegistry}
    var __type: Option[Query.QueryType.EnumVal] = `type`
    var __query: Option[Term] = `query`
    var __token: Option[Long] = `token`
    var __OBSOLETENoreply: Option[Boolean] = `OBSOLETENoreply`
    var __acceptsRJson: Option[Boolean] = `acceptsRJson`
    val __globalOptargs: scala.collection.mutable.Buffer[Query.AssocPair] = `globalOptargs`.toBuffer

    def __newMerged = Query(
      __type,
      __query,
      __token,
      __OBSOLETENoreply,
      __acceptsRJson,
      Vector(__globalOptargs: _*)
    )
    while (true) in.readTag match {
      case 0 => return __newMerged
      case 8 => __type = Some(Query.QueryType.valueOf(in.readEnum()))
      case 18 => __query = Some(readMessage[Term](in, __query.orElse({
	__query = Term.defaultInstance
	__query
      }).get, _emptyRegistry))
      case 24 => __token = Some(in.readInt64())
      case 32 => __OBSOLETENoreply = Some(in.readBool())
      case 40 => __acceptsRJson = Some(in.readBool())
      case 50 => __globalOptargs += readMessage[Query.AssocPair](in, Query.AssocPair.defaultInstance, _emptyRegistry)
      case default => if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: Query) = {
    Query(
      m.`type`.orElse(`type`),
      m.`query`.orElse(`query`),
      m.`token`.orElse(`token`),
      m.`OBSOLETENoreply`.orElse(`OBSOLETENoreply`),
      m.`acceptsRJson`.orElse(`acceptsRJson`),
      `globalOptargs` ++ m.`globalOptargs`
    )
  }

  def getDefaultInstanceForType = Query.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object Query {
  @reflect.BeanProperty val defaultInstance = new Query()

  def parseFrom(data: Array[Byte]): Query = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): Query = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): Query = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): Query = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[Query] = defaultInstance.mergeDelimitedFromStream(stream)

  val TYPE_FIELD_NUMBER = 1
  val QUERY_FIELD_NUMBER = 2
  val TOKEN_FIELD_NUMBER = 3
  val OBSOLETE_NOREPLY_FIELD_NUMBER = 4
  val ACCEPTS_R_JSON_FIELD_NUMBER = 5
  val GLOBAL_OPTARGS_FIELD_NUMBER = 6

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: Query) = defaultInstance.mergeFrom(prototype)

  object QueryType extends net.sandrogrzicic.scalabuff.Enum {
    sealed trait EnumVal extends Value
    val _UNINITIALIZED = new EnumVal { val name = "UNINITIALIZED ENUM VALUE"; val id = -1 }

    val START = new EnumVal { val name = "START"; val id = 1 }
    val CONTINUE = new EnumVal { val name = "CONTINUE"; val id = 2 }
    val STOP = new EnumVal { val name = "STOP"; val id = 3 }
    val NOREPLY_WAIT = new EnumVal { val name = "NOREPLY_WAIT"; val id = 4 }

    val START_VALUE = 1
    val CONTINUE_VALUE = 2
    val STOP_VALUE = 3
    val NOREPLY_WAIT_VALUE = 4

    def valueOf(id: Int) = id match {
      case 1 => START
      case 2 => CONTINUE
      case 3 => STOP
      case 4 => NOREPLY_WAIT
      case _default => throw new net.sandrogrzicic.scalabuff.UnknownEnumException(_default)
    }
    val internalGetValueMap = new com.google.protobuf.Internal.EnumLiteMap[EnumVal] {
      def findValueByNumber(id: Int): EnumVal = valueOf(id)
    }
  }

  final case class AssocPair (
    `key`: Option[String] = None,
    `val`: Option[Term] = None
  ) extends com.google.protobuf.GeneratedMessageLite
      with com.google.protobuf.MessageLite.Builder
      with net.sandrogrzicic.scalabuff.Message[AssocPair]
      with net.sandrogrzicic.scalabuff.Parser[AssocPair] {

    def setKey(_f: String) = copy(`key` = Some(_f))
    def setVal(_f: Term) = copy(`val` = Some(_f))

    def clearKey = copy(`key` = None)
    def clearVal = copy(`val` = None)

    def writeTo(output: com.google.protobuf.CodedOutputStream) {
      if (`key`.isDefined) output.writeString(1, `key`.get)
      if (`val`.isDefined) output.writeMessage(2, `val`.get)
    }

    def getSerializedSize = {
      import com.google.protobuf.CodedOutputStream._
      var __size = 0
      if (`key`.isDefined) __size += computeStringSize(1, `key`.get)
      if (`val`.isDefined) __size += computeMessageSize(2, `val`.get)

      __size
    }

    def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): AssocPair = {
      import com.google.protobuf.ExtensionRegistryLite.{getEmptyRegistry => _emptyRegistry}
      var __key: Option[String] = `key`
      var __val: Option[Term] = `val`

      def __newMerged = AssocPair(
	__key,
	__val
      )
      while (true) in.readTag match {
	case 0 => return __newMerged
	case 10 => __key = Some(in.readString())
	case 18 => __val = Some(readMessage[Term](in, __val.orElse({
	  __val = Term.defaultInstance
	  __val
	}).get, _emptyRegistry))
	case default => if (!in.skipField(default)) return __newMerged
      }
      null
    }

    def mergeFrom(m: AssocPair) = {
      AssocPair(
	m.`key`.orElse(`key`),
	m.`val`.orElse(`val`)
      )
    }

    def getDefaultInstanceForType = AssocPair.defaultInstance
    def clear = getDefaultInstanceForType
    def isInitialized = true
    def build = this
    def buildPartial = this
    def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
    override def getParserForType = this
    def newBuilderForType = getDefaultInstanceForType
    def toBuilder = this
    def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
  }

  object AssocPair {
    @reflect.BeanProperty val defaultInstance = new AssocPair()

    def parseFrom(data: Array[Byte]): AssocPair = defaultInstance.mergeFrom(data)
    def parseFrom(data: Array[Byte], offset: Int, length: Int): AssocPair = defaultInstance.mergeFrom(data, offset, length)
    def parseFrom(byteString: com.google.protobuf.ByteString): AssocPair = defaultInstance.mergeFrom(byteString)
    def parseFrom(stream: java.io.InputStream): AssocPair = defaultInstance.mergeFrom(stream)
    def parseDelimitedFrom(stream: java.io.InputStream): Option[AssocPair] = defaultInstance.mergeDelimitedFromStream(stream)

    val KEY_FIELD_NUMBER = 1
    val VAL_FIELD_NUMBER = 2

    def newBuilder = defaultInstance.newBuilderForType
    def newBuilder(prototype: AssocPair) = defaultInstance.mergeFrom(prototype)

  }
}
final case class Frame (
  `type`: Option[Frame.FrameType.EnumVal] = None,
  `pos`: Option[Long] = None,
  `opt`: Option[String] = None
) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[Frame]
    with net.sandrogrzicic.scalabuff.Parser[Frame] {

  def setType(_f: Frame.FrameType.EnumVal) = copy(`type` = Some(_f))
  def setPos(_f: Long) = copy(`pos` = Some(_f))
  def setOpt(_f: String) = copy(`opt` = Some(_f))

  def clearType = copy(`type` = None)
  def clearPos = copy(`pos` = None)
  def clearOpt = copy(`opt` = None)

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    if (`type`.isDefined) output.writeEnum(1, `type`.get)
    if (`pos`.isDefined) output.writeInt64(2, `pos`.get)
    if (`opt`.isDefined) output.writeString(3, `opt`.get)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    if (`type`.isDefined) __size += computeEnumSize(1, `type`.get)
    if (`pos`.isDefined) __size += computeInt64Size(2, `pos`.get)
    if (`opt`.isDefined) __size += computeStringSize(3, `opt`.get)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): Frame = {
    import com.google.protobuf.ExtensionRegistryLite.{getEmptyRegistry => _emptyRegistry}
    var __type: Option[Frame.FrameType.EnumVal] = `type`
    var __pos: Option[Long] = `pos`
    var __opt: Option[String] = `opt`

    def __newMerged = Frame(
      __type,
      __pos,
      __opt
    )
    while (true) in.readTag match {
      case 0 => return __newMerged
      case 8 => __type = Some(Frame.FrameType.valueOf(in.readEnum()))
      case 16 => __pos = Some(in.readInt64())
      case 26 => __opt = Some(in.readString())
      case default => if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: Frame) = {
    Frame(
      m.`type`.orElse(`type`),
      m.`pos`.orElse(`pos`),
      m.`opt`.orElse(`opt`)
    )
  }

  def getDefaultInstanceForType = Frame.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object Frame {
  @reflect.BeanProperty val defaultInstance = new Frame()

  def parseFrom(data: Array[Byte]): Frame = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): Frame = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): Frame = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): Frame = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[Frame] = defaultInstance.mergeDelimitedFromStream(stream)

  val TYPE_FIELD_NUMBER = 1
  val POS_FIELD_NUMBER = 2
  val OPT_FIELD_NUMBER = 3

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: Frame) = defaultInstance.mergeFrom(prototype)

  object FrameType extends net.sandrogrzicic.scalabuff.Enum {
    sealed trait EnumVal extends Value
    val _UNINITIALIZED = new EnumVal { val name = "UNINITIALIZED ENUM VALUE"; val id = -1 }

    val POS = new EnumVal { val name = "POS"; val id = 1 }
    val OPT = new EnumVal { val name = "OPT"; val id = 2 }

    val POS_VALUE = 1
    val OPT_VALUE = 2

    def valueOf(id: Int) = id match {
      case 1 => POS
      case 2 => OPT
      case _default => throw new net.sandrogrzicic.scalabuff.UnknownEnumException(_default)
    }
    val internalGetValueMap = new com.google.protobuf.Internal.EnumLiteMap[EnumVal] {
      def findValueByNumber(id: Int): EnumVal = valueOf(id)
    }
  }

}
final case class Backtrace (
  `frames`: scala.collection.immutable.Seq[Frame] = Vector.empty[Frame]
) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[Backtrace]
    with net.sandrogrzicic.scalabuff.Parser[Backtrace] {

  def setFrames(_i: Int, _v: Frame) = copy(`frames` = `frames`.updated(_i, _v))
  def addFrames(_f: Frame) = copy(`frames` = `frames` :+ _f)
  def addAllFrames(_f: Frame*) = copy(`frames` = `frames` ++ _f)
  def addAllFrames(_f: TraversableOnce[Frame]) = copy(`frames` = `frames` ++ _f)

  def clearFrames = copy(`frames` = Vector.empty[Frame])

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    for (_v <- `frames`) output.writeMessage(1, _v)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    for (_v <- `frames`) __size += computeMessageSize(1, _v)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): Backtrace = {
    import com.google.protobuf.ExtensionRegistryLite.{getEmptyRegistry => _emptyRegistry}
    val __frames: scala.collection.mutable.Buffer[Frame] = `frames`.toBuffer

    def __newMerged = Backtrace(
      Vector(__frames: _*)
    )
    while (true) in.readTag match {
      case 0 => return __newMerged
      case 10 => __frames += readMessage[Frame](in, Frame.defaultInstance, _emptyRegistry)
      case default => if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: Backtrace) = {
    Backtrace(
      `frames` ++ m.`frames`
    )
  }

  def getDefaultInstanceForType = Backtrace.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object Backtrace {
  @reflect.BeanProperty val defaultInstance = new Backtrace()

  def parseFrom(data: Array[Byte]): Backtrace = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): Backtrace = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): Backtrace = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): Backtrace = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[Backtrace] = defaultInstance.mergeDelimitedFromStream(stream)

  val FRAMES_FIELD_NUMBER = 1

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: Backtrace) = defaultInstance.mergeFrom(prototype)

}
final case class Response (
  `type`: Option[Response.ResponseType.EnumVal] = None,
  `token`: Option[Long] = None,
  `response`: scala.collection.immutable.Seq[Datum] = Vector.empty[Datum],
  `backtrace`: Option[Backtrace] = None,
  `profile`: Option[Datum] = None
) extends com.google.protobuf.GeneratedMessageLite
    with com.google.protobuf.MessageLite.Builder
    with net.sandrogrzicic.scalabuff.Message[Response]
    with net.sandrogrzicic.scalabuff.Parser[Response] {

  def setType(_f: Response.ResponseType.EnumVal) = copy(`type` = Some(_f))
  def setToken(_f: Long) = copy(`token` = Some(_f))
  def setResponse(_i: Int, _v: Datum) = copy(`response` = `response`.updated(_i, _v))
  def addResponse(_f: Datum) = copy(`response` = `response` :+ _f)
  def addAllResponse(_f: Datum*) = copy(`response` = `response` ++ _f)
  def addAllResponse(_f: TraversableOnce[Datum]) = copy(`response` = `response` ++ _f)
  def setBacktrace(_f: Backtrace) = copy(`backtrace` = Some(_f))
  def setProfile(_f: Datum) = copy(`profile` = Some(_f))

  def clearType = copy(`type` = None)
  def clearToken = copy(`token` = None)
  def clearResponse = copy(`response` = Vector.empty[Datum])
  def clearBacktrace = copy(`backtrace` = None)
  def clearProfile = copy(`profile` = None)

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    if (`type`.isDefined) output.writeEnum(1, `type`.get)
    if (`token`.isDefined) output.writeInt64(2, `token`.get)
    for (_v <- `response`) output.writeMessage(3, _v)
    if (`backtrace`.isDefined) output.writeMessage(4, `backtrace`.get)
    if (`profile`.isDefined) output.writeMessage(5, `profile`.get)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    if (`type`.isDefined) __size += computeEnumSize(1, `type`.get)
    if (`token`.isDefined) __size += computeInt64Size(2, `token`.get)
    for (_v <- `response`) __size += computeMessageSize(3, _v)
    if (`backtrace`.isDefined) __size += computeMessageSize(4, `backtrace`.get)
    if (`profile`.isDefined) __size += computeMessageSize(5, `profile`.get)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): Response = {
    import com.google.protobuf.ExtensionRegistryLite.{getEmptyRegistry => _emptyRegistry}
    var __type: Option[Response.ResponseType.EnumVal] = `type`
    var __token: Option[Long] = `token`
    val __response: scala.collection.mutable.Buffer[Datum] = `response`.toBuffer
    var __backtrace: Option[Backtrace] = `backtrace`
    var __profile: Option[Datum] = `profile`

    def __newMerged = Response(
      __type,
      __token,
      Vector(__response: _*),
      __backtrace,
      __profile
    )
    while (true) in.readTag match {
      case 0 => return __newMerged
      case 8 => __type = Some(Response.ResponseType.valueOf(in.readEnum()))
      case 16 => __token = Some(in.readInt64())
      case 26 => __response += readMessage[Datum](in, Datum.defaultInstance, _emptyRegistry)
      case 34 => __backtrace = Some(readMessage[Backtrace](in, __backtrace.orElse({
	__backtrace = Backtrace.defaultInstance
	__backtrace
      }).get, _emptyRegistry))
      case 42 => __profile = Some(readMessage[Datum](in, __profile.orElse({
	__profile = Datum.defaultInstance
	__profile
      }).get, _emptyRegistry))
      case default => if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: Response) = {
    Response(
      m.`type`.orElse(`type`),
      m.`token`.orElse(`token`),
      `response` ++ m.`response`,
      m.`backtrace`.orElse(`backtrace`),
      m.`profile`.orElse(`profile`)
    )
  }

  def getDefaultInstanceForType = Response.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = getDefaultInstanceForType
  def toBuilder = this
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object Response {
  @reflect.BeanProperty val defaultInstance = new Response()

  def parseFrom(data: Array[Byte]): Response = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): Response = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): Response = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): Response = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[Response] = defaultInstance.mergeDelimitedFromStream(stream)

  val TYPE_FIELD_NUMBER = 1
  val TOKEN_FIELD_NUMBER = 2
  val RESPONSE_FIELD_NUMBER = 3
  val BACKTRACE_FIELD_NUMBER = 4
  val PROFILE_FIELD_NUMBER = 5

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: Response) = defaultInstance.mergeFrom(prototype)

  object ResponseType extends net.sandrogrzicic.scalabuff.Enum {
    sealed trait EnumVal extends Value
    val _UNINITIALIZED = new EnumVal { val name = "UNINITIALIZED ENUM VALUE"; val id = -1 }

    val SUCCESS_ATOM = new EnumVal { val name = "SUCCESS_ATOM"; val id = 1 }
    val SUCCESS_SEQUENCE = new EnumVal { val name = "SUCCESS_SEQUENCE"; val id = 2 }
    val SUCCESS_PARTIAL = new EnumVal { val name = "SUCCESS_PARTIAL"; val id = 3 }
    val WAIT_COMPLETE = new EnumVal { val name = "WAIT_COMPLETE"; val id = 4 }
    val CLIENT_ERROR = new EnumVal { val name = "CLIENT_ERROR"; val id = 16 }
    val COMPILE_ERROR = new EnumVal { val name = "COMPILE_ERROR"; val id = 17 }
    val RUNTIME_ERROR = new EnumVal { val name = "RUNTIME_ERROR"; val id = 18 }

    val SUCCESS_ATOM_VALUE = 1
    val SUCCESS_SEQUENCE_VALUE = 2
    val SUCCESS_PARTIAL_VALUE = 3
    val WAIT_COMPLETE_VALUE = 4
    val CLIENT_ERROR_VALUE = 16
    val COMPILE_ERROR_VALUE = 17
    val RUNTIME_ERROR_VALUE = 18

    def valueOf(id: Int) = id match {
      case 1 => SUCCESS_ATOM
      case 2 => SUCCESS_SEQUENCE
      case 3 => SUCCESS_PARTIAL
      case 4 => WAIT_COMPLETE
      case 16 => CLIENT_ERROR
      case 17 => COMPILE_ERROR
      case 18 => RUNTIME_ERROR
      case _default => throw new net.sandrogrzicic.scalabuff.UnknownEnumException(_default)
    }
    val internalGetValueMap = new com.google.protobuf.Internal.EnumLiteMap[EnumVal] {
      def findValueByNumber(id: Int): EnumVal = valueOf(id)
    }
  }

}
final case class Datum (
  `type`: Option[Datum.DatumType.EnumVal] = None,
  `rBool`: Option[Boolean] = None,
  `rNum`: Option[Double] = None,
  `rStr`: Option[String] = None,
  `rArray`: scala.collection.immutable.Seq[Datum] = Vector.empty[Datum],
  `rObject`: scala.collection.immutable.Seq[Datum.AssocPair] = Vector.empty[Datum.AssocPair]
) extends com.google.protobuf.GeneratedMessageLite.ExtendableMessage[Datum]
    with net.sandrogrzicic.scalabuff.ExtendableMessage[Datum]
    with net.sandrogrzicic.scalabuff.Parser[Datum] {

  def setType(_f: Datum.DatumType.EnumVal) = copy(`type` = Some(_f))
  def setRBool(_f: Boolean) = copy(`rBool` = Some(_f))
  def setRNum(_f: Double) = copy(`rNum` = Some(_f))
  def setRStr(_f: String) = copy(`rStr` = Some(_f))
  def setRArray(_i: Int, _v: Datum) = copy(`rArray` = `rArray`.updated(_i, _v))
  def addRArray(_f: Datum) = copy(`rArray` = `rArray` :+ _f)
  def addAllRArray(_f: Datum*) = copy(`rArray` = `rArray` ++ _f)
  def addAllRArray(_f: TraversableOnce[Datum]) = copy(`rArray` = `rArray` ++ _f)
  def setRObject(_i: Int, _v: Datum.AssocPair) = copy(`rObject` = `rObject`.updated(_i, _v))
  def addRObject(_f: Datum.AssocPair) = copy(`rObject` = `rObject` :+ _f)
  def addAllRObject(_f: Datum.AssocPair*) = copy(`rObject` = `rObject` ++ _f)
  def addAllRObject(_f: TraversableOnce[Datum.AssocPair]) = copy(`rObject` = `rObject` ++ _f)

  def clearType = copy(`type` = None)
  def clearRBool = copy(`rBool` = None)
  def clearRNum = copy(`rNum` = None)
  def clearRStr = copy(`rStr` = None)
  def clearRArray = copy(`rArray` = Vector.empty[Datum])
  def clearRObject = copy(`rObject` = Vector.empty[Datum.AssocPair])

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    if (`type`.isDefined) output.writeEnum(1, `type`.get)
    if (`rBool`.isDefined) output.writeBool(2, `rBool`.get)
    if (`rNum`.isDefined) output.writeDouble(3, `rNum`.get)
    if (`rStr`.isDefined) output.writeString(4, `rStr`.get)
    for (_v <- `rArray`) output.writeMessage(5, _v)
    for (_v <- `rObject`) output.writeMessage(6, _v)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    if (`type`.isDefined) __size += computeEnumSize(1, `type`.get)
    if (`rBool`.isDefined) __size += computeBoolSize(2, `rBool`.get)
    if (`rNum`.isDefined) __size += computeDoubleSize(3, `rNum`.get)
    if (`rStr`.isDefined) __size += computeStringSize(4, `rStr`.get)
    for (_v <- `rArray`) __size += computeMessageSize(5, _v)
    for (_v <- `rObject`) __size += computeMessageSize(6, _v)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): Datum = {
    import com.google.protobuf.ExtensionRegistryLite.{getEmptyRegistry => _emptyRegistry}
    var __type: Option[Datum.DatumType.EnumVal] = `type`
    var __rBool: Option[Boolean] = `rBool`
    var __rNum: Option[Double] = `rNum`
    var __rStr: Option[String] = `rStr`
    val __rArray: scala.collection.mutable.Buffer[Datum] = `rArray`.toBuffer
    val __rObject: scala.collection.mutable.Buffer[Datum.AssocPair] = `rObject`.toBuffer

    def __newMerged = Datum(
      __type,
      __rBool,
      __rNum,
      __rStr,
      Vector(__rArray: _*),
      Vector(__rObject: _*)
    )
    while (true) in.readTag match {
      case 0 => return __newMerged
      case 8 => __type = Some(Datum.DatumType.valueOf(in.readEnum()))
      case 16 => __rBool = Some(in.readBool())
      case 25 => __rNum = Some(in.readDouble())
      case 34 => __rStr = Some(in.readString())
      case 42 => __rArray += readMessage[Datum](in, Datum.defaultInstance, _emptyRegistry)
      case 50 => __rObject += readMessage[Datum.AssocPair](in, Datum.AssocPair.defaultInstance, _emptyRegistry)
      case default => if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: Datum) = {
    Datum(
      m.`type`.orElse(`type`),
      m.`rBool`.orElse(`rBool`),
      m.`rNum`.orElse(`rNum`),
      m.`rStr`.orElse(`rStr`),
      `rArray` ++ m.`rArray`,
      `rObject` ++ m.`rObject`
    )
  }

  def getDefaultInstanceForType = Datum.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = throw new RuntimeException("Method not available.")
  def toBuilder = throw new RuntimeException("Method not available.")
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object Datum {
  @reflect.BeanProperty val defaultInstance = new Datum()

  def parseFrom(data: Array[Byte]): Datum = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): Datum = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): Datum = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): Datum = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[Datum] = defaultInstance.mergeDelimitedFromStream(stream)

  val TYPE_FIELD_NUMBER = 1
  val R_BOOL_FIELD_NUMBER = 2
  val R_NUM_FIELD_NUMBER = 3
  val R_STR_FIELD_NUMBER = 4
  val R_ARRAY_FIELD_NUMBER = 5
  val R_OBJECT_FIELD_NUMBER = 6

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: Datum) = defaultInstance.mergeFrom(prototype)

  object DatumType extends net.sandrogrzicic.scalabuff.Enum {
    sealed trait EnumVal extends Value
    val _UNINITIALIZED = new EnumVal { val name = "UNINITIALIZED ENUM VALUE"; val id = -1 }

    val R_NULL = new EnumVal { val name = "R_NULL"; val id = 1 }
    val R_BOOL = new EnumVal { val name = "R_BOOL"; val id = 2 }
    val R_NUM = new EnumVal { val name = "R_NUM"; val id = 3 }
    val R_STR = new EnumVal { val name = "R_STR"; val id = 4 }
    val R_ARRAY = new EnumVal { val name = "R_ARRAY"; val id = 5 }
    val R_OBJECT = new EnumVal { val name = "R_OBJECT"; val id = 6 }
    val R_JSON = new EnumVal { val name = "R_JSON"; val id = 7 }

    val R_NULL_VALUE = 1
    val R_BOOL_VALUE = 2
    val R_NUM_VALUE = 3
    val R_STR_VALUE = 4
    val R_ARRAY_VALUE = 5
    val R_OBJECT_VALUE = 6
    val R_JSON_VALUE = 7

    def valueOf(id: Int) = id match {
      case 1 => R_NULL
      case 2 => R_BOOL
      case 3 => R_NUM
      case 4 => R_STR
      case 5 => R_ARRAY
      case 6 => R_OBJECT
      case 7 => R_JSON
      case _default => throw new net.sandrogrzicic.scalabuff.UnknownEnumException(_default)
    }
    val internalGetValueMap = new com.google.protobuf.Internal.EnumLiteMap[EnumVal] {
      def findValueByNumber(id: Int): EnumVal = valueOf(id)
    }
  }

  final case class AssocPair (
    `key`: Option[String] = None,
    `val`: Option[Datum] = None
  ) extends com.google.protobuf.GeneratedMessageLite
      with com.google.protobuf.MessageLite.Builder
      with net.sandrogrzicic.scalabuff.Message[AssocPair]
      with net.sandrogrzicic.scalabuff.Parser[AssocPair] {

    def setKey(_f: String) = copy(`key` = Some(_f))
    def setVal(_f: Datum) = copy(`val` = Some(_f))

    def clearKey = copy(`key` = None)
    def clearVal = copy(`val` = None)

    def writeTo(output: com.google.protobuf.CodedOutputStream) {
      if (`key`.isDefined) output.writeString(1, `key`.get)
      if (`val`.isDefined) output.writeMessage(2, `val`.get)
    }

    def getSerializedSize = {
      import com.google.protobuf.CodedOutputStream._
      var __size = 0
      if (`key`.isDefined) __size += computeStringSize(1, `key`.get)
      if (`val`.isDefined) __size += computeMessageSize(2, `val`.get)

      __size
    }

    def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): AssocPair = {
      import com.google.protobuf.ExtensionRegistryLite.{getEmptyRegistry => _emptyRegistry}
      var __key: Option[String] = `key`
      var __val: Option[Datum] = `val`

      def __newMerged = AssocPair(
	__key,
	__val
      )
      while (true) in.readTag match {
	case 0 => return __newMerged
	case 10 => __key = Some(in.readString())
	case 18 => __val = Some(readMessage[Datum](in, __val.orElse({
	  __val = Datum.defaultInstance
	  __val
	}).get, _emptyRegistry))
	case default => if (!in.skipField(default)) return __newMerged
      }
      null
    }

    def mergeFrom(m: AssocPair) = {
      AssocPair(
	m.`key`.orElse(`key`),
	m.`val`.orElse(`val`)
      )
    }

    def getDefaultInstanceForType = AssocPair.defaultInstance
    def clear = getDefaultInstanceForType
    def isInitialized = true
    def build = this
    def buildPartial = this
    def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
    override def getParserForType = this
    def newBuilderForType = getDefaultInstanceForType
    def toBuilder = this
    def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
  }

  object AssocPair {
    @reflect.BeanProperty val defaultInstance = new AssocPair()

    def parseFrom(data: Array[Byte]): AssocPair = defaultInstance.mergeFrom(data)
    def parseFrom(data: Array[Byte], offset: Int, length: Int): AssocPair = defaultInstance.mergeFrom(data, offset, length)
    def parseFrom(byteString: com.google.protobuf.ByteString): AssocPair = defaultInstance.mergeFrom(byteString)
    def parseFrom(stream: java.io.InputStream): AssocPair = defaultInstance.mergeFrom(stream)
    def parseDelimitedFrom(stream: java.io.InputStream): Option[AssocPair] = defaultInstance.mergeDelimitedFromStream(stream)

    val KEY_FIELD_NUMBER = 1
    val VAL_FIELD_NUMBER = 2

    def newBuilder = defaultInstance.newBuilderForType
    def newBuilder(prototype: AssocPair) = defaultInstance.mergeFrom(prototype)

  }
}
final case class Term (
  `type`: Option[Term.TermType.EnumVal] = None,
  `datum`: Option[Datum] = None,
  `args`: scala.collection.immutable.Seq[Term] = Vector.empty[Term],
  `optargs`: scala.collection.immutable.Seq[Term.AssocPair] = Vector.empty[Term.AssocPair]
) extends com.google.protobuf.GeneratedMessageLite.ExtendableMessage[Term]
    with net.sandrogrzicic.scalabuff.ExtendableMessage[Term]
    with net.sandrogrzicic.scalabuff.Parser[Term] {

  def setType(_f: Term.TermType.EnumVal) = copy(`type` = Some(_f))
  def setDatum(_f: Datum) = copy(`datum` = Some(_f))
  def setArgs(_i: Int, _v: Term) = copy(`args` = `args`.updated(_i, _v))
  def addArgs(_f: Term) = copy(`args` = `args` :+ _f)
  def addAllArgs(_f: Term*) = copy(`args` = `args` ++ _f)
  def addAllArgs(_f: TraversableOnce[Term]) = copy(`args` = `args` ++ _f)
  def setOptargs(_i: Int, _v: Term.AssocPair) = copy(`optargs` = `optargs`.updated(_i, _v))
  def addOptargs(_f: Term.AssocPair) = copy(`optargs` = `optargs` :+ _f)
  def addAllOptargs(_f: Term.AssocPair*) = copy(`optargs` = `optargs` ++ _f)
  def addAllOptargs(_f: TraversableOnce[Term.AssocPair]) = copy(`optargs` = `optargs` ++ _f)

  def clearType = copy(`type` = None)
  def clearDatum = copy(`datum` = None)
  def clearArgs = copy(`args` = Vector.empty[Term])
  def clearOptargs = copy(`optargs` = Vector.empty[Term.AssocPair])

  def writeTo(output: com.google.protobuf.CodedOutputStream) {
    if (`type`.isDefined) output.writeEnum(1, `type`.get)
    if (`datum`.isDefined) output.writeMessage(2, `datum`.get)
    for (_v <- `args`) output.writeMessage(3, _v)
    for (_v <- `optargs`) output.writeMessage(4, _v)
  }

  def getSerializedSize = {
    import com.google.protobuf.CodedOutputStream._
    var __size = 0
    if (`type`.isDefined) __size += computeEnumSize(1, `type`.get)
    if (`datum`.isDefined) __size += computeMessageSize(2, `datum`.get)
    for (_v <- `args`) __size += computeMessageSize(3, _v)
    for (_v <- `optargs`) __size += computeMessageSize(4, _v)

    __size
  }

  def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): Term = {
    import com.google.protobuf.ExtensionRegistryLite.{getEmptyRegistry => _emptyRegistry}
    var __type: Option[Term.TermType.EnumVal] = `type`
    var __datum: Option[Datum] = `datum`
    val __args: scala.collection.mutable.Buffer[Term] = `args`.toBuffer
    val __optargs: scala.collection.mutable.Buffer[Term.AssocPair] = `optargs`.toBuffer

    def __newMerged = Term(
      __type,
      __datum,
      Vector(__args: _*),
      Vector(__optargs: _*)
    )
    while (true) in.readTag match {
      case 0 => return __newMerged
      case 8 => __type = Some(Term.TermType.valueOf(in.readEnum()))
      case 18 => __datum = Some(readMessage[Datum](in, __datum.orElse({
	__datum = Datum.defaultInstance
	__datum
      }).get, _emptyRegistry))
      case 26 => __args += readMessage[Term](in, Term.defaultInstance, _emptyRegistry)
      case 34 => __optargs += readMessage[Term.AssocPair](in, Term.AssocPair.defaultInstance, _emptyRegistry)
      case default => if (!in.skipField(default)) return __newMerged
    }
    null
  }

  def mergeFrom(m: Term) = {
    Term(
      m.`type`.orElse(`type`),
      m.`datum`.orElse(`datum`),
      `args` ++ m.`args`,
      `optargs` ++ m.`optargs`
    )
  }

  def getDefaultInstanceForType = Term.defaultInstance
  def clear = getDefaultInstanceForType
  def isInitialized = true
  def build = this
  def buildPartial = this
  def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
  override def getParserForType = this
  def newBuilderForType = throw new RuntimeException("Method not available.")
  def toBuilder = throw new RuntimeException("Method not available.")
  def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object Term {
  @reflect.BeanProperty val defaultInstance = new Term()

  def parseFrom(data: Array[Byte]): Term = defaultInstance.mergeFrom(data)
  def parseFrom(data: Array[Byte], offset: Int, length: Int): Term = defaultInstance.mergeFrom(data, offset, length)
  def parseFrom(byteString: com.google.protobuf.ByteString): Term = defaultInstance.mergeFrom(byteString)
  def parseFrom(stream: java.io.InputStream): Term = defaultInstance.mergeFrom(stream)
  def parseDelimitedFrom(stream: java.io.InputStream): Option[Term] = defaultInstance.mergeDelimitedFromStream(stream)

  val TYPE_FIELD_NUMBER = 1
  val DATUM_FIELD_NUMBER = 2
  val ARGS_FIELD_NUMBER = 3
  val OPTARGS_FIELD_NUMBER = 4

  def newBuilder = defaultInstance.newBuilderForType
  def newBuilder(prototype: Term) = defaultInstance.mergeFrom(prototype)

  object TermType extends net.sandrogrzicic.scalabuff.Enum {
    sealed trait EnumVal extends Value
    val _UNINITIALIZED = new EnumVal { val name = "UNINITIALIZED ENUM VALUE"; val id = -1 }

    val DATUM = new EnumVal { val name = "DATUM"; val id = 1 }
    val MAKE_ARRAY = new EnumVal { val name = "MAKE_ARRAY"; val id = 2 }
    val MAKE_OBJ = new EnumVal { val name = "MAKE_OBJ"; val id = 3 }
    val VAR = new EnumVal { val name = "VAR"; val id = 10 }
    val JAVASCRIPT = new EnumVal { val name = "JAVASCRIPT"; val id = 11 }
    val ERROR = new EnumVal { val name = "ERROR"; val id = 12 }
    val IMPLICIT_VAR = new EnumVal { val name = "IMPLICIT_VAR"; val id = 13 }
    val DB = new EnumVal { val name = "DB"; val id = 14 }
    val TABLE = new EnumVal { val name = "TABLE"; val id = 15 }
    val GET = new EnumVal { val name = "GET"; val id = 16 }
    val GET_ALL = new EnumVal { val name = "GET_ALL"; val id = 78 }
    val EQ = new EnumVal { val name = "EQ"; val id = 17 }
    val NE = new EnumVal { val name = "NE"; val id = 18 }
    val LT = new EnumVal { val name = "LT"; val id = 19 }
    val LE = new EnumVal { val name = "LE"; val id = 20 }
    val GT = new EnumVal { val name = "GT"; val id = 21 }
    val GE = new EnumVal { val name = "GE"; val id = 22 }
    val NOT = new EnumVal { val name = "NOT"; val id = 23 }
    val ADD = new EnumVal { val name = "ADD"; val id = 24 }
    val SUB = new EnumVal { val name = "SUB"; val id = 25 }
    val MUL = new EnumVal { val name = "MUL"; val id = 26 }
    val DIV = new EnumVal { val name = "DIV"; val id = 27 }
    val MOD = new EnumVal { val name = "MOD"; val id = 28 }
    val APPEND = new EnumVal { val name = "APPEND"; val id = 29 }
    val PREPEND = new EnumVal { val name = "PREPEND"; val id = 80 }
    val DIFFERENCE = new EnumVal { val name = "DIFFERENCE"; val id = 95 }
    val SET_INSERT = new EnumVal { val name = "SET_INSERT"; val id = 88 }
    val SET_INTERSECTION = new EnumVal { val name = "SET_INTERSECTION"; val id = 89 }
    val SET_UNION = new EnumVal { val name = "SET_UNION"; val id = 90 }
    val SET_DIFFERENCE = new EnumVal { val name = "SET_DIFFERENCE"; val id = 91 }
    val SLICE = new EnumVal { val name = "SLICE"; val id = 30 }
    val SKIP = new EnumVal { val name = "SKIP"; val id = 70 }
    val LIMIT = new EnumVal { val name = "LIMIT"; val id = 71 }
    val INDEXES_OF = new EnumVal { val name = "INDEXES_OF"; val id = 87 }
    val CONTAINS = new EnumVal { val name = "CONTAINS"; val id = 93 }
    val GET_FIELD = new EnumVal { val name = "GET_FIELD"; val id = 31 }
    val KEYS = new EnumVal { val name = "KEYS"; val id = 94 }
    val OBJECT = new EnumVal { val name = "OBJECT"; val id = 143 }
    val HAS_FIELDS = new EnumVal { val name = "HAS_FIELDS"; val id = 32 }
    val WITH_FIELDS = new EnumVal { val name = "WITH_FIELDS"; val id = 96 }
    val PLUCK = new EnumVal { val name = "PLUCK"; val id = 33 }
    val WITHOUT = new EnumVal { val name = "WITHOUT"; val id = 34 }
    val MERGE = new EnumVal { val name = "MERGE"; val id = 35 }
    val BETWEEN = new EnumVal { val name = "BETWEEN"; val id = 36 }
    val REDUCE = new EnumVal { val name = "REDUCE"; val id = 37 }
    val MAP = new EnumVal { val name = "MAP"; val id = 38 }
    val FILTER = new EnumVal { val name = "FILTER"; val id = 39 }
    val CONCATMAP = new EnumVal { val name = "CONCATMAP"; val id = 40 }
    val ORDERBY = new EnumVal { val name = "ORDERBY"; val id = 41 }
    val DISTINCT = new EnumVal { val name = "DISTINCT"; val id = 42 }
    val COUNT = new EnumVal { val name = "COUNT"; val id = 43 }
    val IS_EMPTY = new EnumVal { val name = "IS_EMPTY"; val id = 86 }
    val UNION = new EnumVal { val name = "UNION"; val id = 44 }
    val NTH = new EnumVal { val name = "NTH"; val id = 45 }
    val INNER_JOIN = new EnumVal { val name = "INNER_JOIN"; val id = 48 }
    val OUTER_JOIN = new EnumVal { val name = "OUTER_JOIN"; val id = 49 }
    val EQ_JOIN = new EnumVal { val name = "EQ_JOIN"; val id = 50 }
    val ZIP = new EnumVal { val name = "ZIP"; val id = 72 }
    val INSERT_AT = new EnumVal { val name = "INSERT_AT"; val id = 82 }
    val DELETE_AT = new EnumVal { val name = "DELETE_AT"; val id = 83 }
    val CHANGE_AT = new EnumVal { val name = "CHANGE_AT"; val id = 84 }
    val SPLICE_AT = new EnumVal { val name = "SPLICE_AT"; val id = 85 }
    val COERCE_TO = new EnumVal { val name = "COERCE_TO"; val id = 51 }
    val TYPEOF = new EnumVal { val name = "TYPEOF"; val id = 52 }
    val UPDATE = new EnumVal { val name = "UPDATE"; val id = 53 }
    val DELETE = new EnumVal { val name = "DELETE"; val id = 54 }
    val REPLACE = new EnumVal { val name = "REPLACE"; val id = 55 }
    val INSERT = new EnumVal { val name = "INSERT"; val id = 56 }
    val DB_CREATE = new EnumVal { val name = "DB_CREATE"; val id = 57 }
    val DB_DROP = new EnumVal { val name = "DB_DROP"; val id = 58 }
    val DB_LIST = new EnumVal { val name = "DB_LIST"; val id = 59 }
    val TABLE_CREATE = new EnumVal { val name = "TABLE_CREATE"; val id = 60 }
    val TABLE_DROP = new EnumVal { val name = "TABLE_DROP"; val id = 61 }
    val TABLE_LIST = new EnumVal { val name = "TABLE_LIST"; val id = 62 }
    val SYNC = new EnumVal { val name = "SYNC"; val id = 138 }
    val INDEX_CREATE = new EnumVal { val name = "INDEX_CREATE"; val id = 75 }
    val INDEX_DROP = new EnumVal { val name = "INDEX_DROP"; val id = 76 }
    val INDEX_LIST = new EnumVal { val name = "INDEX_LIST"; val id = 77 }
    val INDEX_STATUS = new EnumVal { val name = "INDEX_STATUS"; val id = 139 }
    val INDEX_WAIT = new EnumVal { val name = "INDEX_WAIT"; val id = 140 }
    val FUNCALL = new EnumVal { val name = "FUNCALL"; val id = 64 }
    val BRANCH = new EnumVal { val name = "BRANCH"; val id = 65 }
    val ANY = new EnumVal { val name = "ANY"; val id = 66 }
    val ALL = new EnumVal { val name = "ALL"; val id = 67 }
    val FOREACH = new EnumVal { val name = "FOREACH"; val id = 68 }
    val FUNC = new EnumVal { val name = "FUNC"; val id = 69 }
    val ASC = new EnumVal { val name = "ASC"; val id = 73 }
    val DESC = new EnumVal { val name = "DESC"; val id = 74 }
    val INFO = new EnumVal { val name = "INFO"; val id = 79 }
    val MATCH = new EnumVal { val name = "MATCH"; val id = 97 }
    val UPCASE = new EnumVal { val name = "UPCASE"; val id = 141 }
    val DOWNCASE = new EnumVal { val name = "DOWNCASE"; val id = 142 }
    val SAMPLE = new EnumVal { val name = "SAMPLE"; val id = 81 }
    val DEFAULT = new EnumVal { val name = "DEFAULT"; val id = 92 }
    val JSON = new EnumVal { val name = "JSON"; val id = 98 }
    val ISO8601 = new EnumVal { val name = "ISO8601"; val id = 99 }
    val TO_ISO8601 = new EnumVal { val name = "TO_ISO8601"; val id = 100 }
    val EPOCH_TIME = new EnumVal { val name = "EPOCH_TIME"; val id = 101 }
    val TO_EPOCH_TIME = new EnumVal { val name = "TO_EPOCH_TIME"; val id = 102 }
    val NOW = new EnumVal { val name = "NOW"; val id = 103 }
    val IN_TIMEZONE = new EnumVal { val name = "IN_TIMEZONE"; val id = 104 }
    val DURING = new EnumVal { val name = "DURING"; val id = 105 }
    val DATE = new EnumVal { val name = "DATE"; val id = 106 }
    val TIME_OF_DAY = new EnumVal { val name = "TIME_OF_DAY"; val id = 126 }
    val TIMEZONE = new EnumVal { val name = "TIMEZONE"; val id = 127 }
    val YEAR = new EnumVal { val name = "YEAR"; val id = 128 }
    val MONTH = new EnumVal { val name = "MONTH"; val id = 129 }
    val DAY = new EnumVal { val name = "DAY"; val id = 130 }
    val DAY_OF_WEEK = new EnumVal { val name = "DAY_OF_WEEK"; val id = 131 }
    val DAY_OF_YEAR = new EnumVal { val name = "DAY_OF_YEAR"; val id = 132 }
    val HOURS = new EnumVal { val name = "HOURS"; val id = 133 }
    val MINUTES = new EnumVal { val name = "MINUTES"; val id = 134 }
    val SECONDS = new EnumVal { val name = "SECONDS"; val id = 135 }
    val TIME = new EnumVal { val name = "TIME"; val id = 136 }
    val MONDAY = new EnumVal { val name = "MONDAY"; val id = 107 }
    val TUESDAY = new EnumVal { val name = "TUESDAY"; val id = 108 }
    val WEDNESDAY = new EnumVal { val name = "WEDNESDAY"; val id = 109 }
    val THURSDAY = new EnumVal { val name = "THURSDAY"; val id = 110 }
    val FRIDAY = new EnumVal { val name = "FRIDAY"; val id = 111 }
    val SATURDAY = new EnumVal { val name = "SATURDAY"; val id = 112 }
    val SUNDAY = new EnumVal { val name = "SUNDAY"; val id = 113 }
    val JANUARY = new EnumVal { val name = "JANUARY"; val id = 114 }
    val FEBRUARY = new EnumVal { val name = "FEBRUARY"; val id = 115 }
    val MARCH = new EnumVal { val name = "MARCH"; val id = 116 }
    val APRIL = new EnumVal { val name = "APRIL"; val id = 117 }
    val MAY = new EnumVal { val name = "MAY"; val id = 118 }
    val JUNE = new EnumVal { val name = "JUNE"; val id = 119 }
    val JULY = new EnumVal { val name = "JULY"; val id = 120 }
    val AUGUST = new EnumVal { val name = "AUGUST"; val id = 121 }
    val SEPTEMBER = new EnumVal { val name = "SEPTEMBER"; val id = 122 }
    val OCTOBER = new EnumVal { val name = "OCTOBER"; val id = 123 }
    val NOVEMBER = new EnumVal { val name = "NOVEMBER"; val id = 124 }
    val DECEMBER = new EnumVal { val name = "DECEMBER"; val id = 125 }
    val LITERAL = new EnumVal { val name = "LITERAL"; val id = 137 }
    val GROUP = new EnumVal { val name = "GROUP"; val id = 144 }
    val SUM = new EnumVal { val name = "SUM"; val id = 145 }
    val AVG = new EnumVal { val name = "AVG"; val id = 146 }
    val MIN = new EnumVal { val name = "MIN"; val id = 147 }
    val MAX = new EnumVal { val name = "MAX"; val id = 148 }
    val SPLIT = new EnumVal { val name = "SPLIT"; val id = 149 }
    val UNGROUP = new EnumVal { val name = "UNGROUP"; val id = 150 }

    val DATUM_VALUE = 1
    val MAKE_ARRAY_VALUE = 2
    val MAKE_OBJ_VALUE = 3
    val VAR_VALUE = 10
    val JAVASCRIPT_VALUE = 11
    val ERROR_VALUE = 12
    val IMPLICIT_VAR_VALUE = 13
    val DB_VALUE = 14
    val TABLE_VALUE = 15
    val GET_VALUE = 16
    val GET_ALL_VALUE = 78
    val EQ_VALUE = 17
    val NE_VALUE = 18
    val LT_VALUE = 19
    val LE_VALUE = 20
    val GT_VALUE = 21
    val GE_VALUE = 22
    val NOT_VALUE = 23
    val ADD_VALUE = 24
    val SUB_VALUE = 25
    val MUL_VALUE = 26
    val DIV_VALUE = 27
    val MOD_VALUE = 28
    val APPEND_VALUE = 29
    val PREPEND_VALUE = 80
    val DIFFERENCE_VALUE = 95
    val SET_INSERT_VALUE = 88
    val SET_INTERSECTION_VALUE = 89
    val SET_UNION_VALUE = 90
    val SET_DIFFERENCE_VALUE = 91
    val SLICE_VALUE = 30
    val SKIP_VALUE = 70
    val LIMIT_VALUE = 71
    val INDEXES_OF_VALUE = 87
    val CONTAINS_VALUE = 93
    val GET_FIELD_VALUE = 31
    val KEYS_VALUE = 94
    val OBJECT_VALUE = 143
    val HAS_FIELDS_VALUE = 32
    val WITH_FIELDS_VALUE = 96
    val PLUCK_VALUE = 33
    val WITHOUT_VALUE = 34
    val MERGE_VALUE = 35
    val BETWEEN_VALUE = 36
    val REDUCE_VALUE = 37
    val MAP_VALUE = 38
    val FILTER_VALUE = 39
    val CONCATMAP_VALUE = 40
    val ORDERBY_VALUE = 41
    val DISTINCT_VALUE = 42
    val COUNT_VALUE = 43
    val IS_EMPTY_VALUE = 86
    val UNION_VALUE = 44
    val NTH_VALUE = 45
    val INNER_JOIN_VALUE = 48
    val OUTER_JOIN_VALUE = 49
    val EQ_JOIN_VALUE = 50
    val ZIP_VALUE = 72
    val INSERT_AT_VALUE = 82
    val DELETE_AT_VALUE = 83
    val CHANGE_AT_VALUE = 84
    val SPLICE_AT_VALUE = 85
    val COERCE_TO_VALUE = 51
    val TYPEOF_VALUE = 52
    val UPDATE_VALUE = 53
    val DELETE_VALUE = 54
    val REPLACE_VALUE = 55
    val INSERT_VALUE = 56
    val DB_CREATE_VALUE = 57
    val DB_DROP_VALUE = 58
    val DB_LIST_VALUE = 59
    val TABLE_CREATE_VALUE = 60
    val TABLE_DROP_VALUE = 61
    val TABLE_LIST_VALUE = 62
    val SYNC_VALUE = 138
    val INDEX_CREATE_VALUE = 75
    val INDEX_DROP_VALUE = 76
    val INDEX_LIST_VALUE = 77
    val INDEX_STATUS_VALUE = 139
    val INDEX_WAIT_VALUE = 140
    val FUNCALL_VALUE = 64
    val BRANCH_VALUE = 65
    val ANY_VALUE = 66
    val ALL_VALUE = 67
    val FOREACH_VALUE = 68
    val FUNC_VALUE = 69
    val ASC_VALUE = 73
    val DESC_VALUE = 74
    val INFO_VALUE = 79
    val MATCH_VALUE = 97
    val UPCASE_VALUE = 141
    val DOWNCASE_VALUE = 142
    val SAMPLE_VALUE = 81
    val DEFAULT_VALUE = 92
    val JSON_VALUE = 98
    val ISO8601_VALUE = 99
    val TO_ISO8601_VALUE = 100
    val EPOCH_TIME_VALUE = 101
    val TO_EPOCH_TIME_VALUE = 102
    val NOW_VALUE = 103
    val IN_TIMEZONE_VALUE = 104
    val DURING_VALUE = 105
    val DATE_VALUE = 106
    val TIME_OF_DAY_VALUE = 126
    val TIMEZONE_VALUE = 127
    val YEAR_VALUE = 128
    val MONTH_VALUE = 129
    val DAY_VALUE = 130
    val DAY_OF_WEEK_VALUE = 131
    val DAY_OF_YEAR_VALUE = 132
    val HOURS_VALUE = 133
    val MINUTES_VALUE = 134
    val SECONDS_VALUE = 135
    val TIME_VALUE = 136
    val MONDAY_VALUE = 107
    val TUESDAY_VALUE = 108
    val WEDNESDAY_VALUE = 109
    val THURSDAY_VALUE = 110
    val FRIDAY_VALUE = 111
    val SATURDAY_VALUE = 112
    val SUNDAY_VALUE = 113
    val JANUARY_VALUE = 114
    val FEBRUARY_VALUE = 115
    val MARCH_VALUE = 116
    val APRIL_VALUE = 117
    val MAY_VALUE = 118
    val JUNE_VALUE = 119
    val JULY_VALUE = 120
    val AUGUST_VALUE = 121
    val SEPTEMBER_VALUE = 122
    val OCTOBER_VALUE = 123
    val NOVEMBER_VALUE = 124
    val DECEMBER_VALUE = 125
    val LITERAL_VALUE = 137
    val GROUP_VALUE = 144
    val SUM_VALUE = 145
    val AVG_VALUE = 146
    val MIN_VALUE = 147
    val MAX_VALUE = 148
    val SPLIT_VALUE = 149
    val UNGROUP_VALUE = 150

    def valueOf(id: Int) = id match {
      case 1 => DATUM
      case 2 => MAKE_ARRAY
      case 3 => MAKE_OBJ
      case 10 => VAR
      case 11 => JAVASCRIPT
      case 12 => ERROR
      case 13 => IMPLICIT_VAR
      case 14 => DB
      case 15 => TABLE
      case 16 => GET
      case 78 => GET_ALL
      case 17 => EQ
      case 18 => NE
      case 19 => LT
      case 20 => LE
      case 21 => GT
      case 22 => GE
      case 23 => NOT
      case 24 => ADD
      case 25 => SUB
      case 26 => MUL
      case 27 => DIV
      case 28 => MOD
      case 29 => APPEND
      case 80 => PREPEND
      case 95 => DIFFERENCE
      case 88 => SET_INSERT
      case 89 => SET_INTERSECTION
      case 90 => SET_UNION
      case 91 => SET_DIFFERENCE
      case 30 => SLICE
      case 70 => SKIP
      case 71 => LIMIT
      case 87 => INDEXES_OF
      case 93 => CONTAINS
      case 31 => GET_FIELD
      case 94 => KEYS
      case 143 => OBJECT
      case 32 => HAS_FIELDS
      case 96 => WITH_FIELDS
      case 33 => PLUCK
      case 34 => WITHOUT
      case 35 => MERGE
      case 36 => BETWEEN
      case 37 => REDUCE
      case 38 => MAP
      case 39 => FILTER
      case 40 => CONCATMAP
      case 41 => ORDERBY
      case 42 => DISTINCT
      case 43 => COUNT
      case 86 => IS_EMPTY
      case 44 => UNION
      case 45 => NTH
      case 48 => INNER_JOIN
      case 49 => OUTER_JOIN
      case 50 => EQ_JOIN
      case 72 => ZIP
      case 82 => INSERT_AT
      case 83 => DELETE_AT
      case 84 => CHANGE_AT
      case 85 => SPLICE_AT
      case 51 => COERCE_TO
      case 52 => TYPEOF
      case 53 => UPDATE
      case 54 => DELETE
      case 55 => REPLACE
      case 56 => INSERT
      case 57 => DB_CREATE
      case 58 => DB_DROP
      case 59 => DB_LIST
      case 60 => TABLE_CREATE
      case 61 => TABLE_DROP
      case 62 => TABLE_LIST
      case 138 => SYNC
      case 75 => INDEX_CREATE
      case 76 => INDEX_DROP
      case 77 => INDEX_LIST
      case 139 => INDEX_STATUS
      case 140 => INDEX_WAIT
      case 64 => FUNCALL
      case 65 => BRANCH
      case 66 => ANY
      case 67 => ALL
      case 68 => FOREACH
      case 69 => FUNC
      case 73 => ASC
      case 74 => DESC
      case 79 => INFO
      case 97 => MATCH
      case 141 => UPCASE
      case 142 => DOWNCASE
      case 81 => SAMPLE
      case 92 => DEFAULT
      case 98 => JSON
      case 99 => ISO8601
      case 100 => TO_ISO8601
      case 101 => EPOCH_TIME
      case 102 => TO_EPOCH_TIME
      case 103 => NOW
      case 104 => IN_TIMEZONE
      case 105 => DURING
      case 106 => DATE
      case 126 => TIME_OF_DAY
      case 127 => TIMEZONE
      case 128 => YEAR
      case 129 => MONTH
      case 130 => DAY
      case 131 => DAY_OF_WEEK
      case 132 => DAY_OF_YEAR
      case 133 => HOURS
      case 134 => MINUTES
      case 135 => SECONDS
      case 136 => TIME
      case 107 => MONDAY
      case 108 => TUESDAY
      case 109 => WEDNESDAY
      case 110 => THURSDAY
      case 111 => FRIDAY
      case 112 => SATURDAY
      case 113 => SUNDAY
      case 114 => JANUARY
      case 115 => FEBRUARY
      case 116 => MARCH
      case 117 => APRIL
      case 118 => MAY
      case 119 => JUNE
      case 120 => JULY
      case 121 => AUGUST
      case 122 => SEPTEMBER
      case 123 => OCTOBER
      case 124 => NOVEMBER
      case 125 => DECEMBER
      case 137 => LITERAL
      case 144 => GROUP
      case 145 => SUM
      case 146 => AVG
      case 147 => MIN
      case 148 => MAX
      case 149 => SPLIT
      case 150 => UNGROUP
      case _default => throw new net.sandrogrzicic.scalabuff.UnknownEnumException(_default)
    }
    val internalGetValueMap = new com.google.protobuf.Internal.EnumLiteMap[EnumVal] {
      def findValueByNumber(id: Int): EnumVal = valueOf(id)
    }
  }

  final case class AssocPair (
    `key`: Option[String] = None,
    `val`: Option[Term] = None
  ) extends com.google.protobuf.GeneratedMessageLite
      with com.google.protobuf.MessageLite.Builder
      with net.sandrogrzicic.scalabuff.Message[AssocPair]
      with net.sandrogrzicic.scalabuff.Parser[AssocPair] {

    def setKey(_f: String) = copy(`key` = Some(_f))
    def setVal(_f: Term) = copy(`val` = Some(_f))

    def clearKey = copy(`key` = None)
    def clearVal = copy(`val` = None)

    def writeTo(output: com.google.protobuf.CodedOutputStream) {
      if (`key`.isDefined) output.writeString(1, `key`.get)
      if (`val`.isDefined) output.writeMessage(2, `val`.get)
    }

    def getSerializedSize = {
      import com.google.protobuf.CodedOutputStream._
      var __size = 0
      if (`key`.isDefined) __size += computeStringSize(1, `key`.get)
      if (`val`.isDefined) __size += computeMessageSize(2, `val`.get)

      __size
    }

    def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): AssocPair = {
      import com.google.protobuf.ExtensionRegistryLite.{getEmptyRegistry => _emptyRegistry}
      var __key: Option[String] = `key`
      var __val: Option[Term] = `val`

      def __newMerged = AssocPair(
	__key,
	__val
      )
      while (true) in.readTag match {
	case 0 => return __newMerged
	case 10 => __key = Some(in.readString())
	case 18 => __val = Some(readMessage[Term](in, __val.orElse({
	  __val = Term.defaultInstance
	  __val
	}).get, _emptyRegistry))
	case default => if (!in.skipField(default)) return __newMerged
      }
      null
    }

    def mergeFrom(m: AssocPair) = {
      AssocPair(
	m.`key`.orElse(`key`),
	m.`val`.orElse(`val`)
      )
    }

    def getDefaultInstanceForType = AssocPair.defaultInstance
    def clear = getDefaultInstanceForType
    def isInitialized = true
    def build = this
    def buildPartial = this
    def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
    override def getParserForType = this
    def newBuilderForType = getDefaultInstanceForType
    def toBuilder = this
    def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
  }

  object AssocPair {
    @reflect.BeanProperty val defaultInstance = new AssocPair()

    def parseFrom(data: Array[Byte]): AssocPair = defaultInstance.mergeFrom(data)
    def parseFrom(data: Array[Byte], offset: Int, length: Int): AssocPair = defaultInstance.mergeFrom(data, offset, length)
    def parseFrom(byteString: com.google.protobuf.ByteString): AssocPair = defaultInstance.mergeFrom(byteString)
    def parseFrom(stream: java.io.InputStream): AssocPair = defaultInstance.mergeFrom(stream)
    def parseDelimitedFrom(stream: java.io.InputStream): Option[AssocPair] = defaultInstance.mergeDelimitedFromStream(stream)

    val KEY_FIELD_NUMBER = 1
    val VAL_FIELD_NUMBER = 2

    def newBuilder = defaultInstance.newBuilderForType
    def newBuilder(prototype: AssocPair) = defaultInstance.mergeFrom(prototype)

  }
}

object Ql2 {
  def registerAllExtensions(registry: com.google.protobuf.ExtensionRegistryLite) {
  }

}
